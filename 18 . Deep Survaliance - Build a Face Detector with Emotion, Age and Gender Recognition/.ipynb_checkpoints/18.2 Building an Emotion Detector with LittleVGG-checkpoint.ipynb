{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using LittleVGG for Emotion Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Emotion Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 3589 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "\n",
    "num_classes = 7\n",
    "img_rows, img_cols = 48, 48\n",
    "batch_size = 16\n",
    "\n",
    "train_data_dir = './fer2013/train'\n",
    "validation_data_dir = './fer2013/validation'\n",
    "\n",
    "# Let's use some data augmentaiton \n",
    "train_datagen = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=30,\n",
    "      shear_range=0.3,\n",
    "      zoom_range=0.3,\n",
    "      width_shift_range=0.4,\n",
    "      height_shift_range=0.4,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    " \n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    " \n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)\n",
    " \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Keras Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import ELU\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras LittleVGG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 48, 48, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 48, 48, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 6, 6, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 6, 6, 256)         590080    \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3, 3, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2304)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                147520    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 455       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 7)                 0         \n",
      "=================================================================\n",
      "Total params: 1,328,167\n",
      "Trainable params: 1,325,991\n",
      "Non-trainable params: 2,176\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding = 'same', kernel_initializer=\"he_normal\",\n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3, 3), padding = \"same\", kernel_initializer=\"he_normal\", \n",
    "                 input_shape = (img_rows, img_cols, 1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #2: second CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #3: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #4: third CONV => RELU => CONV => RELU => POOL\n",
    "# layer set\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(256, (3, 3), padding=\"same\", kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block #5: first set of FC => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #6: second set of FC => RELU layers\n",
    "model.add(Dense(64, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Block #7: softmax classifier\n",
    "model.add(Dense(num_classes, kernel_initializer=\"he_normal\"))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 1795 steps\n",
      "1795/1795 [==============================] - 607s 338ms/step - loss: 2.0255 - accuracy: 0.2012\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "                     \n",
    "checkpoint = ModelCheckpoint(\"emotion_little_vgg.h5\",\n",
    "                             monitor=\"val_loss\",\n",
    "                             mode=\"min\",\n",
    "                             save_best_only = True,\n",
    "                             verbose=1)\n",
    "\n",
    "earlystop = EarlyStopping(monitor = 'val_loss', \n",
    "                          min_delta = 0, \n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
    "\n",
    "# we put our call backs into a callback list\n",
    "callbacks = [earlystop, checkpoint] #reduce_lr]\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adam(lr=0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "epochs = 5\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs = epochs)\n",
    "    callbacks = callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "Confusion Matrix\n",
      "[[  0   0   0 439   0  52   0]\n",
      " [  0   0   0  52   0   3   0]\n",
      " [  0   0   0 486   0  42   0]\n",
      " [  0   0   0 790   0  89   0]\n",
      " [  0   0   0 565   0  61   0]\n",
      " [  0   0   0 496   0  98   0]\n",
      " [  0   0   0 401   0  15   0]]\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.00      0.00      0.00       491\n",
      "     Disgust       0.00      0.00      0.00        55\n",
      "        Fear       0.00      0.00      0.00       528\n",
      "       Happy       0.24      0.90      0.38       879\n",
      "     Neutral       0.00      0.00      0.00       626\n",
      "         Sad       0.27      0.16      0.21       594\n",
      "    Surprise       0.00      0.00      0.00       416\n",
      "\n",
      "    accuracy                           0.25      3589\n",
      "   macro avg       0.07      0.15      0.08      3589\n",
      "weighted avg       0.10      0.25      0.13      3589\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\cv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAHHCAYAAACbaKDRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3debglVXnv8e8PZFAREBCCgOKAUxwQUCESgxoTp4hjnHJFQtLG2Rhzg8NVork3Js6axKQjKniNI0FwuAoiOJAANtiCiCIiSgcCNggOINrd7/2j6tDb9gzd5+yza1fx/TxPPadqVe3aa/dw3v2uWkOqCkmSNH226roCkiRpdgZpSZKmlEFakqQpZZCWJGlKGaQlSZpSBmlJkqbUrbqugCRJS/X7D79tXXPt+rHf99zzb/pcVT167DfeTAZpSVLvXXPtes753J3Gft+t9/zObmO/6RYwSEuSeq+ADWzouhpj5zNpSZKmlJm0JGkAivVlJi1JkibETFqS1HvNM+nhLRhlkJYkDYIdxyRJ0sSYSUuSeq8o1tfwmrvNpCVJmlJm0pKkQbDjmCRJU6iA9QMM0jZ3S5I0pcykJUmDMMTmbjNpSZKmlJm0JKn3CgY5BMsgLUkahOHNN2ZztyRJU8tMWpLUe0U5BEuSJE2OmbQkqf8K1g8vkTaTliRpWplJS5J6rxhm726DtCRpAMJ60nUlxs7mbkmSppSZtCSp9wrYYMcxSZI0KWbSkqRBGOIzaYO0JKn3imEGaZu7JUmaUmbSkqRB2FBm0pIkaULMpCVJvTfUZ9IGaUlS7xVh/QAbh4f3iSRJGggzaUnSINhxTJIkTYyZtCSp9+w4JknS1Arra3iNw8P7RJIkDYSZtCSp9wrYMMC8c3ifSJKkgTCTliQNwhA7jplJS5I0pcykJUm9V2XvbkmSptYGMvZtIUnumWT1yPbjJC9LskuSU5N8p/15+/b6JHlnkkuSnJ/kgPnub5CWJGmRqurbVbV/Ve0PHAjcAJwIHA2cVlX7Aae1xwCPAfZrtxXAu+e7v0FaktR7zYxjW41920KPBL5bVd8HDgeOa8uPA57Y7h8OHF+Ns4Cdk+w51w0N0pIkzW23JKtGthXzXPsM4EPt/h5VdSVA+3P3tnwv4PKR16xpy2ZlxzFJ0gAsW8extVV10ILvnmwLPAF45UKXzlJWc11skJYk9d4UzDj2GOC8qrqqPb4qyZ5VdWXbnH11W74G2GfkdXsDV8x1U5u7JUlaumeysakb4GTgiHb/COCkkfLntL28Dwaun2kWn42ZtCRpENZXNzOOJbkN8CjgeSPFbwQ+muQo4AfA09ryzwCPBS6h6Ql+5Hz3NkhLkrQEVXUDsOsmZdfQ9Pbe9NoCXri59zZIS5J6r8hihkxNPYO0JGkQNjgtqCRJmhQzaUlS783MODY0w/tEkiQNhJm0JKn3inQ2BGs5LUsmneRJSSrJvZbj/pIk3RIsV3P3M4Gv0Ew2vmRJzPglSfPawFZj37o29uCXZAfgocDDaaY/OybJYcAxwFrgvsC5wB9VVSV5LPDW9tx5wF2r6vFJjgHuCOwLrE2yD/Diqlrdvs+ZwPOr6vxxfwZJUr9UsVwLbHRqOTLUJwKfraqLk1yb5IC2/IHAb9JMJH4m8NAkq4B/AR5WVd9L8qFN7nUgcGhV3ZjkCOC5wMuS3APYbq4A3S4ltgJga7Y+8DbsOOaPKG10051v03UVxma779/QdRXGKrcaTiNcrVvXdRXG4uf8jF/UTcN7eLxMluNf8DOBt7f7H26PPw2cU1VrAJKspsmQfwpcWlXfa6//EG1wbZ1cVTe2+x8D/leSvwT+GHj/XBWoqpXASoAds0s9JL82M5s0Nhe/dsFV7HrjHn+yqusqjNXWu+2+8EU9sf6qqxe+qAfOrtOW6c5hw6yrQPbbWIN0kl2BRwD3TVLA1jTD1z4D3DRy6fr2vRf6E/3ZzE5V3ZDkVOBw4A+B4fxmlCRpFuPOpJ8KHF9VN68EkuSLwKFzXP8t4K5J9q2qy4CnL3D/9wCfBL5cVdeOob6SpAEofCa9OZ5JszzXqBOA5wPf3fTi9lnzC4DPJlkLnDPfzavq3CQ/Bt43pvpKkgZiiDOOjTVIV9Vhs5S9E3jnJmUvGjk8varulSTAPwKr2muO2fReSe5IM2zslPHVWpKk6TQNXzv+tO1IdiGwE01v71+T5DnA2cCrq2rDBOsnSZpyRdhQ49+61vn4hKp6G/C2zbjueOD45a+RJEnTofMgLUnSOPhMWpKkKVTAhgH27h7eJ5IkaSDMpCVJAxDWD3DGMTNpSZKmlJm0JKn3fCYtSZImykxakjQIQ3wmbZCWJPVeVWzuliRJk2MmLUkahCEuVTm8TyRJ0kCYSUuSeq+ADXYckyRpGsXmbkmSNDlm0pKk3mtmHLO5W9Im7v3qH3RdhbFZ33UFxmz9VVd3XQVpSQzSkqRBWD/AJ7gGaUlS7xUZZHP38L52SJI0EGbSkqRB2DDAvHN4n0iSpIEwk5Yk9V4VrPeZtCRJmhQzaUnSIAyxd7dBWpLUe80QrOE1Dg/vE0mSNBBm0pKkQVg/wKUqzaQlSZpSBmlJUu/NrII17m1zJNk5yceTfCvJRUkOSbJLklOTfKf9efv22iR5Z5JLkpyf5ID57m2QliQNQNNxbNzbZnoH8NmquhfwAOAi4GjgtKraDzitPQZ4DLBfu60A3j3fjQ3SkiQtUpIdgYcBxwJU1S+q6jrgcOC49rLjgCe2+4cDx1fjLGDnJHvOdX+DtCRpEDaQsW+b4a7AD4H3JflakvckuS2wR1VdCdD+3L29fi/g8pHXr2nLZmWQliRpbrslWTWyrdjk/K2AA4B3V9UDgZ+xsWl7NrNF/prrYodgSZJ6bxnn7l5bVQfNc34NsKaqzm6PP04TpK9KsmdVXdk2Z189cv0+I6/fG7hirpubSUuSBqGLjmNV9d/A5Unu2RY9EvgmcDJwRFt2BHBSu38y8Jy2l/fBwPUzzeKzMZOWJGlpXgx8MMm2wKXAkTRJ8EeTHAX8AHhae+1ngMcClwA3tNfOySAtSeq9Zu7ubmYcq6rVwGxN4o+c5doCXri597a5W5KkKWUmLUkahM0cMtUrW5xJJ1mfZHWSC5N8PcnLk2zVnjsoyTvHX81fq8O+SZ613O8jSVKXFpNJ31hV+wMk2R34N2An4HVVtQpYNcb6zWVf4Fnte0uSbuFm5u4emiU9k66qq2nmHn1R2538sCSfAkjyO23GvbqdheV2SbZK8k9tFv6pJJ9J8tT2+suS7NbuH5TkjLnuA7wR+O227M+X8hkkScPQ4dzdy2bJz6Sr6tK2uXv3TU69AnhhVZ2ZZAfg58CTabLg+7XXXwS8d4G3mO0+RwOvqKrHz/aCdkaYFQDbc5tFfS5Jkro2rq8Js7UxnAm8NclLgJ2rah1wKPCxqtrQDgA/fTPuPdt95lVVK6vqoKo6aBu224KPIUnqpWVYpnIams+XHKST3BVYz8YpzwCoqjcCfwLcGjgryb2YPZjPWDdSn+0XuI8kSYO3pCCd5A7APwP/0A7QHj13t6q6oKr+jqYz2b2ArwBPaZ9N7wEcNvKSy4AD2/2nLHCfnwC3W0rdJUnDUXS2CtayWswz6VsnWQ1sQ5P9fgB46yzXvSzJw2my7G8C/w/4Jc0MLN8ALgbOBq5vr/9r4Ngkr2rL57vPBmBdkq8D76+qty3ic0iSBmQamqfHbYuDdFVtPc+5M4Az2v0Xz3ZNkldU1U+T7AqcA1zQXv9l4B6z3HPW+zDLdGuSJA1JFzOOfSrJzsC2wBvaDmSSJC3aUMdJTzxIV9Vhk35PSZL6yLm7JUmDYCYtSdIU6nKpyuXU/ZxnkiRpVmbSkqRBmIZxzeNmJi1J0pQyk5Yk9V8Ns+OYmbQkSVPKTFqS1HtOZiJJ0hQbYpC2uVuSpCllJi1J6j0nM5EkSRNlJi1JGoQaYCZtkJYkDYIzjkmSpIkxk5Yk9V4545gkSZokM2lpiS591x5dV2Fs7vyHV3ddhbHaetdduq7C2Ky/5tquqzD17DgmSdJUcpy0JEmaIDNpSdIgDLG520xakqQpZSYtSeq9oS5VaSYtSdKUMpOWJPVfNROaDI1BWpI0CM7dLUmSJsZMWpLUe4VDsCRJ0gSZSUuSBmCY04IapCVJgzDE3t02d0uSNKXMpCVJg2DHMUmS9CuSXJbkgiSrk6xqy3ZJcmqS77Q/b9+WJ8k7k1yS5PwkB8x3b4O0JKn3qppMetzbFnh4Ve1fVQe1x0cDp1XVfsBp7THAY4D92m0F8O75bmqQliQNwobK2LclOBw4rt0/DnjiSPnx1TgL2DnJnnPdxCAtSdLSFHBKknOTrGjL9qiqKwHan7u35XsBl4+8dk1bNis7jkmSBmGZhmDtNvOcubWyqlZucs1Dq+qKJLsDpyb51jz3my09n7PmBmlJkua2duQ586yq6or259VJTgQeDFyVZM+qurJtzr66vXwNsM/Iy/cGrpjr3jZ3S5IGoYuOY0lum+R2M/vA7wHfAE4GjmgvOwI4qd0/GXhO28v7YOD6mWbx2Uw0k06yHrhgpOiJVXXZJOsgSRqeYot7Y4/LHsCJSaCJqf9WVZ9N8lXgo0mOAn4APK29/jPAY4FLgBuAI+e7+aSbu2+sqv3HdbM0fyqpqg3juqckSZurqi4FHjBL+TXAI2cpL+CFm3v/zpu7k2yd5E1JvtoO7H5eW75DktOSnNcOEj+8Ld83yUVJ/gk4j19t25ck3ULVMmxdm3Qmfeskq9v971XVk4CjaNrkH5RkO+DMJKfQdFF/UlX9OMluwFlJTm5fe0/gyKp6wWxv0naBXwGwPbdZzs8jSdKymYbm7t8D7p/kqe3xTjQzsawB/k+ShwEbaMaR7dFe8/12EPis2u7xKwF2zC7T8GVIkrScaphzd0/DEKwAL66qz/1KYfJc4A7AgVX1yySXAdu3p3820RpKktSBzp9JA58Dnp9kG4Ak92i7se8EXN0G6IcDd+6ykpKkKTfAh9LTkEm/B9gXOK/trf1DmjlOPwh8sp3pZTUw3wwukqRbOJu7l6iqdpilbAPwqnbb1CFz3Oq+46yXJEnTaBoyaUmSlmyZ5u7u1DQ8k5YkSbMwk5Yk9V7hM2lJkqZTAQMM0jZ3S5I0pcykJUmDYMcxSZI0MWbSkqRhGGAmbZCWJA1ABtm72+ZuSZKmlJm0JGkYBtjcbSYtSdKUMpOWJPVfDXPGMTNpSZKmlJm0JGkYBvhM2iAtSRoIm7slSdKEmElLkoZhgM3dZtKSJE0pM2lpib516Ae6rsLY/D77d12F8dr19l3XYHyuubbrGky/AWbSBmlJUv8V4DhpSZI0KWbSkqRBqAE2d5tJS5I0pcykJUnDMMBM2iAtSRoGO45JkqRJMZOWJA1CBtjcbSYtSdKUMpOWJPVfMciOY2bSkiRNKTNpSdIAZJC9uw3SkqRhsLlbkiRNipm0JGkYzKQlSdKkmElLkoZhgJm0QVqS1H/FIHt329wtSdKUMkhLkgYhNf5ts9432TrJ15J8qj2+S5Kzk3wnyUeSbNuWb9ceX9Ke33ehexukJUlampcCF40c/x3wtqraD/gRcFRbfhTwo6q6O/C29rp5GaQlScNQy7AtIMnewOOA97THAR4BfLy95Djgie3+4e0x7flHttfPaWxBOslPNzl+bpJ/GNf9JUmaQm8H/iewoT3eFbiuqta1x2uAvdr9vYDLAdrz17fXz8lMWpKkue2WZNXItmLmRJLHA1dX1bkj18+WGddmnJvVRIZgJfkD4DXAtsA1wLOr6qokxwB3o/l2sQ/w91X1r0kOA17fXntP4EvAC4AjgftW1Z+39/1T4N5V9fJJfA5J0vTa3I5eW2htVR00x7mHAk9I8lhge2BHmsx65yS3arPlvYEr2uvX0MS6NUluBewEXDvfm48zk751ktUzG02QnfEV4OCqeiDwYZqmgRn3p2nPPwR4bZI7tuUPBv4CuB9NIH9y+9onJNmmveZI4H2bViTJiplvPb/kpvF9QkmSWlX1yqrau6r2BZ4BfKGqng2cDjy1vewI4KR2/+T2mPb8F6pqYpn0jVW1/8xBkucCM98+9gY+kmRPmmz6eyOvO6mqbgRuTHI6TXC+Djinqi5t7/Uh4NCq+niSLwCPT3IRsE1VXbBpRapqJbASYMfsMsA5aCRJv2Z6JjP5K+DDSf4G+BpwbFt+LPCBJJfQZNDPWOhGk5px7F3AW6vq5LYp+5iRc5sG0Vqg/D3Aq4BvMUsWLUnSpFXVGcAZ7f6lNAnnptf8HHjaltx3Uh3HdgL+q90/YpNzhyfZPsmuwGHAV9vyB7cDwrcCnk7TZE5VnU3Tpv8s4EPLXXFJUg8sx/CrKWiHnVSQPgb4WJIvA2s3OXcO8GngLOANVTXzgP0/gTcC36BpHj9x5DUfBc6sqh8tZ6UlST0ywCA9tubuqtphk+P3A+9v909i44PzTV1cVStmKb+hqp4+x2sOpZmtRZKkwerVOOkkOye5mKaT2mld10eSND26mrt7OXW6VGVVHTNH+Rm0D+A3Kb8OuMeyVkqSpCnhetKSpGGYgsx33AzSkqRhGGCQ7tUzaUmSbknMpCVJvTctHb3GzUxakqQpZSYtSRqG6Zm7e2wM0pKkYbC5W5IkTYqZtCRpEOw4JkmSJsZMWpI0DGbSkiRpUsykJUn9N9DJTAzSkqRhGGCQtrlbkqQpZSYtSRoGM2lJkjQpZtLSEj3hO4/uugpj9N9dV2Cs8rMbu66CJmiIHcfMpCVJmlIGaUmSppTN3ZKkYbC5W5IkTYqZtCSp/5xxTJKkKTbAIG1ztyRJU8pMWpI0DGbSkiRpUsykJUm9F4bZccxMWpKkKWUmLUkahgFm0gZpSVL/DXSctM3dkiRNKTNpSdIwmElLkqRJMZOWJA3DADNpg7QkaRDsOCZJkibGTFqSNAxm0pIkaVLMpCVJ/VeYSc9IUkneMnL8iiTHLPJeOyd5wSJfe1mS3RbzWknSsKTGv3Vtsc3dNwFPHlOA3BmYNUgn2XoM95ckaeySbJ/knCRfT3Jhkr9uy++S5Owk30nykSTbtuXbtceXtOf3Xeg9Fhuk1wErgT+fpdJ3SHJCkq+220Pb8mOSvGLkum+0FXwjcLckq5O8KclhSU5P8m/ABe21n0hybvuHsGKRdZYkDVktwza/m4BHVNUDgP2BRyc5GPg74G1VtR/wI+Co9vqjgB9V1d2Bt7XXzWspHcf+EXh2kp02KX9HW7kHAU8B3rPAfY4GvltV+1fVX7ZlDwZeXVX3aY//uKoOBA4CXpJk1/lumGRFklVJVv2Sm7bkM0mStFmq8dP2cJt2K+ARwMfb8uOAJ7b7h7fHtOcfmSTzvceiO45V1Y+THA+8BLhx5NTvAvcZed8dk9xuC29/TlV9b+T4JUme1O7vA+wHXDNP3VbSZPrsmF2m4KmCJGm5dfEMuX0sey5wd5rk9bvAdVW1rr1kDbBXu78XcDlAVa1Lcj2wK7B2rvsvtXf324HzgPeNlG0FHFJVo4GbJOv41cx9+3nu+7OR1x1GE/gPqaobkpyxwGslSRqX3ZKsGjle2SaCAFTVemD/JDsDJwL3nuUeM18fZsua5/1qsaRx0lV1LfBRNra3A5wCvGjmIMn+7e5lwAFt2QHAXdrynwDzZdo70bTh35DkXsDBS6mzJGmglueZ9NqqOmhkW8ksquo64AyaGLVzkpkkeG/ginZ/DU1rMO35nYBr5/tI45jM5C3AaC/vlwAHJTk/yTeBP2vLTwB2SbIaeD5wMUBVXQOc2XYke9Ms9/8scKsk5wNvAM4aQ50lSUOyHAF6gebztqP0zu3+rWlafS8CTgee2l52BHBSu39ye0x7/gtVNe+7LKq5u6p2GNm/CrjNyPFa4OmzvOZG4PfmuN+zNik6Y+TcTcBj5njdvltQbUmSxmlP4Lj2ufRWwEer6lNtgvrhJH8DfA04tr3+WOADSS6hyaCfsdAbOOOYJKn3wuwPfJdTVZ0PPHCW8ktpRiltWv5z4Glb8h7O3S1J0pQyk5YkDcMAB9wapCVJgzANc22Pm83dkiRNKTNpSdIwmElLkqRJMZOWJA3DADNpg7Qkqf/KjmOSJGmCzKQlScNgJi1JkibFTFqSNAg+k5YkSRNjJi1JGoYBZtIGaUnSINjcLUmSJsZMWpLUf8Ugm7vNpCVJmlJm0tISfXftrl1XYWz25r+7rsJY1U47dF2F8fmvrivQAwPMpA3SkqTeC3YckyRJE2QmLUkaBjNpSZI0KWbSkqRBSA0vlTZIS5L6z3HSkiRpksykJUmD4BAsSZI0MWbSkqRhGGAmbZCWJA2Czd2SJGlizKQlScNgJi1JkibFTFqS1H/lM2lJkjRBZtKSpGEYYCZtkJYk9V6wuVuSJE2QmbQkaRgGuFSlmbQkSVPKTFqSNAg+kx6zJK9OcmGS85OsTvKQzXzdvkm+sdz1kyT1RC3T1rHOMukkhwCPBw6oqpuS7AZs21V9JEmaNl02d+8JrK2qmwCqai1AktcCfwDcGvgP4HlVVUkOBN4L3AB8pZsqS5KmVTZ0XYPx67K5+xRgnyQXJ/mnJL/Tlv9DVT2oqu5LE6gf35a/D3hJVR2y0I2TrEiyKsmqX3LT8tRekqRl1lmQrqqfAgcCK4AfAh9J8lzg4UnOTnIB8AjgN5PsBOxcVV9sX/6BBe69sqoOqqqDtmG75fsQkqTp4TPp8aqq9cAZwBltUH4ecH/goKq6PMkxwPY0k8lMwR+XJGladdG7O8k+wPHAbwAbgJVV9Y4kuwAfAfYFLgP+sKp+lCTAO4DH0jy+fW5VnTfX/TvLpJPcM8l+I0X7A99u99cm2QF4KkBVXQdcn+TQ9vyzJ1dTSZLmtA74i6q6N3Aw8MIk9wGOBk6rqv2A09pjgMcA+7XbCuDd8928y0x6B+BdSXam+ZCX0FT4OuACmm8eXx25/kjgvUluAD432apKkqZa0cmMY1V1JXBlu/+TJBcBewGHA4e1lx1H02r8V2358VVVwFlJdk6yZ3ufX9NZkK6qc4HfmuXUa9pttusfMFJ0zPLUTJKkLZdkX+CBwNnAHjOBt6quTLJ7e9lewOUjL1vTlk1XkJYkaZyW6Zn0bklWjRyvrKqVv/bezSPaE4CXVdWPm0fPs5rtxJw1N0hLkjS3tVV10HwXJNmGJkB/sKr+vS2+aqYZO8mewNVt+Rpgn5GX7w1cMde9XWBDkjQMHQzBantrHwtcVFVvHTl1MnBEu38EcNJI+XPSOBi4fq7n0WAmLUkagNDZAhsPBf4HcEGS1W3Zq4A3Ah9NchTwA+Bp7bnP0Ay/uoRmCNaR893cIC1J0iJV1VeY/TkzwCNnub6AF27u/Q3SkqT+q+pkCNZy85m0JElTykxakjQIHT2TXlYGaUnSMAwwSNvcLUnSlDKTliQNwhCbu82kJUmaUmbSkqT+K2DD8FJpg7QkaRiGF6Nt7pYkaVqZSUuSBsGOY5IkaWLMpCVJw+Dc3ZIkaVLMpKUl+vnlt+u6CprDhu9c1nUVNEFDfCZtkJYk9V/hECxJkjQ5ZtKSpN4LEDuOSZKkSTGTliQNw4auKzB+BmlJ0iDY3C1JkibGTFqS1H8OwZIkSZNkJi1JGoAa5NzdBmlJ0iAMcVpQm7slSZpSZtKSpGEYYHO3mbQkSVPKTFqS1H8FGeCMY2bSkiRNKTNpSdIwDPCZtEFakjQMw4vRNndLkjStzKQlSYPgKliSJGlizKQlScNwS82kk7w6yYVJzk+yOslDlqMyST6TZOfluLckacAK2LAMW8cWzKSTHAI8Hjigqm5Kshuw7ebcPMmtqmrdZlwXIFX12M25ryRJtwSbk0nvCaytqpsAqmptVV2R5LI2YJPkoCRntPvHJFmZ5BTg+CTPTXJSks8m+XaS17XX7ZvkoiT/BJwH7DNzzyS3TfLpJF9P8o0kT29fc2CSLyY5N8nnkuw5/j8SSVLfhCI1/q1rm/NM+hTgtUkuBj4PfKSqvrjAaw4EDq2qG5M8F3gwcF/gBuCrST4NrAXuCRxZVS8AaBJqAB4NXFFVj2vLd0qyDfAu4PCq+mEbuP838MebvnmSFcCK9vCnn6+Pf3szPudS7EbzeYbAz7KlXvrxZX8LJvRZLlvuN2hM7t/YL5b9Hfz/suXuPIH3GIwFg3RV/TTJgcBvAw8HPpLk6AVednJV3ThyfGpVXQOQ5N+BQ4FPAN+vqrNmef0FwJuT/B3wqar6cpL70gT6U9tgvjVw5Rx1XgmsXOizjUuSVVV10KTebzn5WaaTn2U6+VmmzBRkvuO2Wb27q2o9cAZwRpILgCOAdWxsLt9+k5f8bNNbzHG86XUz73dx+8XgscDftk3nJwIXVtUhm1NnSdItzACD9ILPpJPcM8l+I0X7A9+naRk7sC17ygK3eVSSXZLcGngicOYC73lH4Iaq+r/Am4EDgG8Dd2g7spFkmyS/uVD9JUnqq83JpHcA3tUOjVoHXELzvPfewLFJXgWcvcA9vgJ8ALg78G9VtSrJvvNcfz/gTUk2AL8Enl9Vv0jyVOCdSXZq6/524MLN+AzLbWJN6xPgZ5lOfpbp5GeZFjNDsAYmtczNA23HsYOq6kXL+kaSpFusnW5zxzr4nn869vuesvr153b5rN5pQSVJg9DFEKwk701ydZJvjJTtkuTUJN9pf96+LU+Sdya5pJ0c7ICF7r/sQbqq3m8WLUkaqPfTDBsedTRwWlXtB5zWHgM8Btiv3VYA717o5mbSkqRhqBr/tuBb1peAazcpPhw4rt0/jqbD9Ez58dU4C9h5oUm5DNKL0I7ZHowkL92csmnXNiXt03U9JHVhGQL04vts7VFVVwK0P3dvy/cCLh+5bk1bNieD9OL8c5JzkrxgIAuCHDFL2XMnXYmlqqYX5Ce6rse4JHlz34cZts/m5ty6rt+WSHJB+xxx1q3r+i1Gkj2SHJvk/7XH90lyVNf1mjK7JVk1sq1Y+CVzyixl834TcKnKRaiqQ9ux438MrEpyDvC+qjq146ptkSTPBJ4F3CXJySOndgSu6aZWS3ZWkgdV1Ve7rsgYfAtYmeRWwPuAD1XV9R3XaUudS/NLaK5fTnedbJJWAskAAA4rSURBVHWW5PHtzxe2Pz/Q/nw2zZTHffR+mn9br26PLwY+AhzbVYUWrViuyUzWLqJ391VJ9qyqK9vm7Kvb8jXAaGvf3sAV893IIL1IVfWdJK8BVgHvBB6YZr7SV1XVv3dbu832HzRTq+4GvGWk/CdALzMDmqlrn5fk+zQz2oUmyb5/t9XaclX1HuA9Se4JHAmcn+RM4F+r6vRua7d5quouXddhXKrq+wBJHlpVDx05dXT79/L6bmq2JLtV1UeTvBKgqtYlWd91pQbgZJoWyje2P08aKX9Rkg8DDwGun2kWn4tBehGS3J/ml+bjgFOBP6iq89qZ0v4T6EWQbn/pfD/J7wI3VtWGJPcA7kUzf3ofPabrCoxTkq1p/j7uRbP4wdeBlyd5XlU9o9PKbaF2GMp+jEwj3Ha66ZvbJjm0qr4CkOS3gNt2XKfF+lmSXWmbXJMcDPSttWajDiYzSfIh4DCaZvE1wOtogvNH20cHPwCe1l7+GZrpri+haX05cqH7G6QX5x+Af6XJmm9eSKRdwvM13VVr0b4E/Hb7S/Q0mtaBp9M04/XKSLazO78+p3yvJHkr8ASav5P/U1XntKf+Lslyr+w2Vkn+BHgpTfPeauBgmi+0j+iyXot0FPDeduZDgOuYZTW+nng5TXZ3t7Y14A7AU7ut0uJ1sbRkVT1zjlOPnOXaYuPjks1ikN5CbWZzeVV9YLbzc5VPuVTVDe23vndV1d8n+VrXlVqMJE+gabq/I81zoDsDFwF97ID1DeA1VTXb884HT7oyS/RS4EHAWVX18CT3Av664zotSlWdCzwgyY40/3d6m3m2LYC/Q7NscIBvV9UvO66WRhikt1BVrU+ya5Jtq2r5V6udjLQLlzybJkuA/v7beANNlvb5qnpgkocDc33TnXbvA56U5FCa5sivVNWJAD0MDD+vqp8nIcl2VfWt9ll7LyV5HM0Xv+2brihQVb17Jp3kacBnq+rCthXwgCR/U1XndV23RRngKlh9/UXcte8DZ7Y9om9ebrOq3tpdlZbkZcArgRPb/6x3BXrRMWkWv6yqa5JslWSrqjo9zbrkffSPNIvSfKg9fl6S362qLWoumxJr2uGKn6BZE/5HLNCrdVol+WfgNjSdFN9D0zx8zrwvml7/q6o+1n4R/H2aVQffTdOpSVPAIL04V7TbVsDtOq7LklXVF4EvjhxfCrykuxotyXVJdgC+DHwwydU0q7f10e8A922fY5HkOHraoa+qntTuHpPkdGAn4LMdVmkpfquq7p/k/Kr66yRvoSedRWcx05P7ccC7q+qkJMd0WJ/FK2CDmbSAqurls7S5tL80f+1fd1X1sVPP4cCNNK0Dz6YJBr1rhmx9G7gTTcsNNOMrezc0LslWwPlVdV+4+Uthn810Fr2hHdFxLdDXoWb/leRfgN+l6ZC4Hb2d5GpJM4RNLYP0IiT5JL8e1K6n6RX9L1X188nXakleMbK/PfAUepp9VtXPktwZ2K+qjktyG2Drruu1SLsCF7WT5UDT8eo/ZyaeqaondFazLdAO7ft6kjtV1Q+6rs8YfKptuv97mslaoGn27qM/pFkc4s1VdV078cZfdlwnjTBIL86lNEMVZp4VPh24CrgHzdCs/9FRvRal7a066swkvcx2kvwpzeoyuwB3o5kX95+ZZThED7y26wqM0Z7Ahe0XjtF+HL34ogGQ5EE0Izve0B7vQPP44VvA27qs25ZKsmNV/ZjmS/kZbdkuwE00yUY/mUmr9cCqetjI8SeTfKmqHpbkws5qtUibzKG8FXAg8BsdVWepXkgzPOlsuHlmuN3nf8l0qqovJvkNms9TwFer6r87rtZiDeER0UyzMEkeRjNhxYuB/YGV9Gt88b/RTHM627StfZuuddAM0otzh9GmuyR3oplaE6CPw7JG/6OuA77HxqFYfXNTVf1iZlhMO+91L79etxOAvBb4As3fzbuSvL6q3tttzRblsVX1V6MFba/7PrXYbF1VM0sSPh1YWVUnACckWd1hvbZYVT2+ncb4dwbyCKJhJq3WXwBfSfJdml+edwFekOS2bFxDtDeGNL8y8MUkrwJuneRRwAuAT3Zcp8X6S5pWm2sA2ukb/wPoY5B+FPBXm5Q9ZpayabZ1kltV1TqaxyejqyH17ndpVVWSE2lazjSlevcPaxpU1WfSrIJ1L5og/a2RzmJv765mi5PkybMUXw9cUFVXz3Jumh1N0wpwAfA8mrly+9qpZw3NYiczfsKvrkU79ZI8n+aL0t3yq8s53o7mC0effIjmS+Bamh7eXwZIcnf6O9/1cFaNG+gQrNQAmwcmoZ1Uf19GvuhU1fGdVWgJknwaOISNE5gcBpxF0xHu9X2Y6nRAPYdvluR44H40K+gUzfCyc2iWE+zF5Dnt/Na3B/6W5gvUjJ+MNB33RrsAxZ7AKVX1s7bsHsAOfZylK8k3af6f937VuJ2226N+647jX27gs5e97dxFLFU5NmbSi5DkAzQ9h1ezcTKAAnoZpGnWjrl3VV0FzULwbJx16EtsXDd3mn0COAAgyQlV9ZSO6zMO3223GTPL3fVmAp12+tLrk2zarL1Dkh369sWqqs6apeziLuoyJoNaNW6IDNKLcxBwnxpOM8S+MwG6dTVwj6q6NklfJtsf7Z06iJ6pA5s059Ns7Jy4PU0/jm/Tz4VPBqOqvp/kAGBmfvgz+9gicLPB/EreyCC9ON+gGaI072LdPfLlJJ8CPtYePxX4UtsR7rruqrVFao793kpyB+B/0i7kMFPex5ngqup+o8dtYHheR9VRK8lradY6npnW9H1JPlZVf9NhtTTCIL04uwHfbCdmuKktq6o6vMM6LcULgSfTfJsOTQ/1E9qWgod3WbEt8IAkP6ap/63bfdj4jG3H7qq2aB8EPkIznvXPgCOAH3ZaozFpl0h8UNf1EM+kGUHwc4AkbwTOA/oXpAfaccwgvTjHjOyHJrj1dTlEaFb0+URVndAuH3hPmn8bfWnqpqr6OvXnfHatqmOTvHRmEZQezwT38pHDrWj6DwziC0fPXUbTSjMzOmU7frUfRL/Y3C24eSao/YFn0cx9+z2aqSf76kvAbye5PfB5mmkBn06zQIW6M/Ml6cp2/eIrgL07rM9SjHZ2W0fzjPqEjuqijW6ima71VJpc9FE0c0C8E6Cq+roa3mAYpLdAO9TiGTRZ8zU0TZGpqr40Cc8lVXVDkqOAd1XV3yf5WteVEn/TDmH6C+BdwI7An3dbpcWZ6QSX5LYzQ5c0FU5stxlndFSP8TCTvsX7Fs0EBn9QVZcAJOnlL81NJMkhNJnzzHSg/tvoWFV9qt29nv70DZhV++/rWGAH4E5JHgA8r6pe0G3NbrmSbA08qqr+qOu6aG7+It4yT6HJpE9P8lngw/zq0J++ehnwSuDEqrowyV3ZOLGJJizJu5inh3pPmyDfDvw+MLPM5tfbRSrUkapan+QOSbatqj6uObAJ15O+xauqE4ET26FJT6RpetwjybtpAtwpnVZwkWY6JY0cXwr0MRAMxehSgX8NvK6rioxTVV0+s/BJa/1c12piLqNZmvZkfnUJ0amfze7XFLBhQ9e1GDuD9CK0z9Q+CHywXebxaTRTHvYqSCd5e1W9LMknmSVz69Nav0NSVTcv0pLkZaPHPXZ5O5VuJdmW5kvgRR3XSU1nxCtoetz3Zia7WxKD9BK18w//S7v1zcx0n2/utBaaz1Da7/4MeAewF83CIafQjM9XhwY2q53N3RqWqjq3/fnFdnYrqsqxqxq7qlqLQ/qmTpLTmb0VrXez2g2VQfoWrF30/XXAi2g6wG2VZB3NMKzXd1q5W7AkP2HjL87b9Hn2tHbayblUVb1hYpXRbF4xsr89TefYdR3VZenMpDUwLwMeCjyoqr4H0PbsfneSP6+qt3Vau1uoqhrSs8HZxkTflmao366AQbpDM61pI87s66x2Q2WQvmV7Ds04ybUzBVV1aZI/onlmaJDWklTVW2b2k9wOeClwJM3wxbfM9TpNRtvxdcZWNCv8/UZH1Vmicu5uDc42owF6RlX9MMk2XVRIw9MGgpfTPJM+Djigqn7Uba3UOpeNj1bW0QzJOmrOq6dZQZVDsDQs801gMIDJDdS1JG+iWWFtJXC/qvppx1US0K5AdnlV3aU9PoLmefRlwDc7rJo2sVXXFVCnHpDkx7NsPwHut+CrpYX9BXBH4DXAFaP/xkY6xGny/oX2i3g789vf0rRyXE/zhaqfNtT4t46ZSd+CDXR5R02RqjIRmE5bt3M8QLPi3cqqOgE4IcnqDuulTfgfSJJuebZOMpOkPRL4wsi5/iZvVePfOtbfvwxJ0mJ9CPhikrXAjTSr+5Hk7jRN3v1T5dzdkqT+q6r/neQ0YE/glKqbU8atgBd3VzNtyiAtSbdAVXXWLGUXd1GXsZmC5ulx85m0JElTykxakjQI5TNpSZKm0XT0xh43m7slSZpSZtKSpP4rpmKGsHEzk5YkaUqZSUuShmGAq2CZSUuSNKXMpCVJvVdADfCZtEFaktR/VTZ3S5KkjZI8Osm3k1yS5Ohx399MWpI0CJNu7k6yNfCPwKOANcBXk5xcVd8c13uYSUuStDgPBi6pqkur6hfAh4HDx/kGZtKSpGGY/DPpvYDLR47XAA8Z5xsYpCVJvfcTfvS5z9fHd1uGW2+fZNXI8cqqWtnuZ5brx9rmbpCWJPVeVT26g7ddA+wzcrw3cMU438Bn0pIkLc5Xgf2S3CXJtsAzgJPH+QZm0pIkLUJVrUvyIuBzwNbAe6vqwnG+R2qA629KkjQENndLkjSlDNKSJE0pg7QkSVPKIC1J0pQySEuSNKUM0pIkTSmDtCRJU8ogLUnSlPr/Z6bR2NdNyw4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "nb_train_samples = 28273\n",
    "nb_validation_samples = 3534\n",
    "\n",
    "# We need to recreate our validation generator with shuffle = false\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(validation_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(validation_generator.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = list(class_labels.values())\n",
    "print(classification_report(validation_generator.classes, y_pred, target_names=target_names))\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "cnf_matrix = confusion_matrix(validation_generator.classes, y_pred)\n",
    "\n",
    "plt.imshow(cnf_matrix, interpolation='nearest')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(classes))\n",
    "_ = plt.xticks(tick_marks, classes, rotation=90)\n",
    "_ = plt.yticks(tick_marks, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading our saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "classifier = load_model('emotion_little_vgg.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get our class labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3589 images belonging to 7 classes.\n",
      "{0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Neutral', 5: 'Sad', 6: 'Surprise'}\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode = 'grayscale',\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "\n",
    "class_labels = validation_generator.class_indices\n",
    "class_labels = {v: k for k, v in class_labels.items()}\n",
    "classes = list(class_labels.values())\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's test on some of validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import RMSprop, SGD, Adam\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "\n",
    "def draw_test(name, pred, im, true_label):\n",
    "    BLACK = [0,0,0]\n",
    "    expanded_image = cv2.copyMakeBorder(im, 160, 0, 0, 300 ,cv2.BORDER_CONSTANT,value=BLACK)\n",
    "    cv2.putText(expanded_image, \"predited - \"+ pred, (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,255), 2)\n",
    "    cv2.putText(expanded_image, \"true - \"+ true_label, (20, 120) , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    cv2.imshow(name, expanded_image)\n",
    "\n",
    "\n",
    "def getRandomImage(path, img_width, img_height):\n",
    "    \"\"\"function loads a random images from a random folder in our test path \"\"\"\n",
    "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
    "    random_directory = np.random.randint(0,len(folders))\n",
    "    path_class = folders[random_directory]\n",
    "    file_path = path + path_class\n",
    "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
    "    random_file_index = np.random.randint(0,len(file_names))\n",
    "    image_name = file_names[random_file_index]\n",
    "    final_path = file_path + \"/\" + image_name\n",
    "    return image.load_img(final_path, target_size = (img_width, img_height),grayscale=True), final_path, path_class\n",
    "\n",
    "# dimensions of our images\n",
    "img_width, img_height = 48, 48\n",
    "\n",
    "# We use a very small learning rate \n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = RMSprop(lr = 0.001),\n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "files = []\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "# predicting images\n",
    "for i in range(0, 10):\n",
    "    path = './fer2013/validation/' \n",
    "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
    "    files.append(final_path)\n",
    "    true_labels.append(true_label)\n",
    "    x = image.img_to_array(img)\n",
    "    x = x * 1./255\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size = 10)\n",
    "    predictions.append(classes)\n",
    "    \n",
    "for i in range(0, len(files)):\n",
    "    image = cv2.imread((files[i]))\n",
    "    image = cv2.resize(image, None, fx=3, fy=3, interpolation = cv2.INTER_CUBIC)\n",
    "    draw_test(\"Prediction\", class_labels[predictions[i][0]], image, true_labels[i])\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img.copy(),cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    allfaces = []   \n",
    "    rects = []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "        allfaces.append(roi_gray)\n",
    "        rects.append((x,w,y,h))\n",
    "    return rects, allfaces, img\n",
    "\n",
    "img = cv2.imread(\"rajeev.jpg\")\n",
    "rects, faces, image = face_detector(img)\n",
    "\n",
    "i = 0\n",
    "for face in faces:\n",
    "    roi = face.astype(\"float\") / 255.0\n",
    "    roi = img_to_array(roi)\n",
    "    roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "    # make a prediction on the ROI, then lookup the class\n",
    "    preds = classifier.predict(roi)[0]\n",
    "    label = class_labels[preds.argmax()]   \n",
    "\n",
    "    #Overlay our detected emotion on our pic\n",
    "    label_position = (rects[i][0] + int((rects[i][1]/2)), abs(rects[i][2] - 10))\n",
    "    i =+ 1\n",
    "    cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,1, (0,255,0), 2)\n",
    "    \n",
    "cv2.imshow(\"Emotion Detector\", image)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try this on our webcam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('./Haarcascades/haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return (0,0,0,0), np.zeros((48,48), np.uint8), img\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "        roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "    try:\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), interpolation = cv2.INTER_AREA)\n",
    "    except:\n",
    "        return (x,w,y,h), np.zeros((48,48), np.uint8), img\n",
    "    return (x,w,y,h), roi_gray, img\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    rect, face, image = face_detector(frame)\n",
    "    if np.sum([face]) != 0.0:\n",
    "        roi = face.astype(\"float\") / 255.0\n",
    "        roi = img_to_array(roi)\n",
    "        roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "        # make a prediction on the ROI, then lookup the class\n",
    "        preds = classifier.predict(roi)[0]\n",
    "        label = class_labels[preds.argmax()]  \n",
    "        label_position = (rect[0] + int((rect[1]/2)), rect[2] + 25)\n",
    "        cv2.putText(image, label, label_position , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "    else:\n",
    "        cv2.putText(image, \"No Face Found\", (20, 60) , cv2.FONT_HERSHEY_SIMPLEX,2, (0,255,0), 3)\n",
    "        \n",
    "    cv2.imshow('All', image)\n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
